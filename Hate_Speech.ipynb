{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pathu564/Cyber-Bullying-Detection-for-Code-Mixed-Texts/blob/main/Hate_Speech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLQr_v-8_GfE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After executing this, restart the session and then re run 1st cell and skip this cell"
      ],
      "metadata": {
        "id": "GwfCBIlvyIHL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LBk7RtrC-1n"
      },
      "outputs": [],
      "source": [
        "!pip install numpy==1.24.3 --force-reinstall --no-cache-dir\n",
        "!pip install transformers==4.30.2 --force-reinstall --no-cache-dir\n",
        "!pip install gensim joblib ipywidgets --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3aS9FU4CYXA"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "print(\"‚úÖ NumPy Version:\", numpy.__version__)\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "print(\"‚úÖ Transformers import successful\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnERlldztEqp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# pre-train your dataset with appropriate embeddings and use them here\n",
        "mtext_df = pd.read_csv(\"/content/drive/MyDrive/bully_detection/muril_embeddings_final.csv\")\n",
        "emoji_df = pd.read_csv(\"/content/drive/MyDrive/bully_detection/emoji_embeddings.csv\")\n",
        "\n",
        "print(\"üîπ First row of TEXT dataset:\")\n",
        "print(mtext_df.head(1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vbeR8Z3-cJ9"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "X_text = mtext_df.drop(columns=[\"Text\", \"Label\"])\n",
        "y_text = mtext_df[\"Label\"]\n",
        "\n",
        "X_emoji = emoji_df.drop(columns=[\"Emoji\", \"Label\"])\n",
        "y_emoji = emoji_df[\"Label\"]\n",
        "\n",
        "X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(\n",
        "    X_text, y_text, test_size=0.2, random_state=42, stratify=y_text\n",
        ")\n",
        "\n",
        "X_emoji_train, X_emoji_test, y_emoji_train, y_emoji_test = train_test_split(\n",
        "    X_emoji, y_emoji, test_size=0.2, random_state=42, stratify=y_emoji\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Train-test split completed successfully!\")\n",
        "print(\"üîπ X_text_train:\", X_text_train.shape, \"| y_text_train:\", y_text_train.shape)\n",
        "print(\"üîπ X_emoji_train:\", X_emoji_train.shape, \"| y_emoji_train:\", y_emoji_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Huu-OMS-xig"
      },
      "outputs": [],
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "smote_tomek = SMOTETomek(random_state=42)\n",
        "X_text_train_resampled, y_text_train_resampled = smote_tomek.fit_resample(X_text_train, y_text_train)\n",
        "\n",
        "print(\"‚úÖ SMOTE-Tomek applied on text dataset!\")\n",
        "print(\"üîπ X_text_train_resampled:\", X_text_train_resampled.shape, \"| y_text_train_resampled:\", y_text_train_resampled.shape)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "np.save(\"m_X_text_train_resampled.npy\", X_text_train_resampled)\n",
        "np.save(\"m_y_text_train_resampled.npy\", y_text_train_resampled)\n",
        "\n",
        "np.save(\"/content/drive/MyDrive/bully_detection/f_X_emoji_train.npy\", X_emoji_train)\n",
        "np.save(\"/content/drive/MyDrive/bully_detection/f_y_emoji_train.npy\", y_emoji_train)\n",
        "\n",
        "\n",
        "print(\"‚úÖ Processed data saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mGrUiUp_DXY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Save test dataset to files\n",
        "np.save(\"m_X_text_test.npy\", X_text_test)\n",
        "np.save(\"m_y_text_test.npy\", y_text_test)\n",
        "\n",
        "np.save(\"/content/drive/MyDrive/bully_detection/X_emoji_test.npy\", X_emoji_test)\n",
        "np.save(\"/content/drive/MyDrive/bully_detection/y_emoji_test.npy\", y_emoji_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UodTGe79A5hJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Load from your path\n",
        "X_train = np.load('m_X_text_train_resampled.npy')\n",
        "y_train = np.load('m_y_text_train_resampled.npy')\n",
        "X_test = np.load('m_X_text_test.npy')\n",
        "y_test = np.load('m_y_text_test.npy')\n",
        "\n",
        "# Convert to tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# Check shape\n",
        "print(f\"Train: {X_train_tensor.shape}, Test: {X_test_tensor.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DConvBilSTM Architecture"
      ],
      "metadata": {
        "id": "NIFe9P6pt3zL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGm0PBs79piV"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class DConvBiLSTM(nn.Module):\n",
        "    def __init__(self, input_dim=768, hidden_dim=128, output_dim=2, dropout_rate=0.5):\n",
        "        super(DConvBiLSTM, self).__init__()\n",
        "        self.depthwise_conv = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, padding=1, groups=1)\n",
        "        self.bilstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim,\n",
        "                              num_layers=1, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)  # [batch, 1, 768]\n",
        "        x = self.depthwise_conv(x)  # [batch, 1, 768]\n",
        "        x = x.squeeze(1).unsqueeze(1)  # [batch, 1, 768]\n",
        "        lstm_out, _ = self.bilstm(x)\n",
        "        out = lstm_out[:, -1, :]  # Take last time step\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Classification Model(DConvBiLSTM) Training"
      ],
      "metadata": {
        "id": "akrC1wFRt-TZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nVNVC2uBXK9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = DConvBiLSTM().to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 1500\n",
        "# Make sure to upload the model file to your Google Drive and update this path accordingly\n",
        "checkpoint_path = \"/content/drive/MyDrive/bully_detection/Dconvbilstm_checkpoint.pth\"\n",
        "final_model_path = \"/content/drive/MyDrive/bully_detection/Dconvbilstm_bully_model.pth\"\n",
        "log_path = \"/content/drive/MyDrive/bully_detection/loss_accuracy_log.txt\"\n",
        "\n",
        "loss_history = []\n",
        "accuracy_history = []\n",
        "\n",
        "start_epoch = 0\n",
        "if os.path.exists(checkpoint_path):\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    print(f\"‚úÖ Resumed from epoch {start_epoch}\")\n",
        "else:\n",
        "    print(\"üì¶ Starting from scratch\")\n",
        "\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        predicted = torch.argmax(outputs, dim=1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    loss_history.append(avg_loss)\n",
        "    accuracy_history.append(accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {avg_loss:.4f} | Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': avg_loss\n",
        "        }, checkpoint_path)\n",
        "        print(f\"üìå Checkpoint saved at epoch {epoch+1}\")\n",
        "\n",
        "torch.save(model.state_dict(), final_model_path)\n",
        "print(\"üéØ Final model saved!\")\n",
        "\n",
        "with open(log_path, \"w\") as f:\n",
        "    for i, (l, acc) in enumerate(zip(loss_history, accuracy_history)):\n",
        "        f.write(f\"Epoch {i+1}, Loss: {l:.4f}, Accuracy: {acc:.4f}\\n\")\n",
        "print(\"üìù Loss & accuracy log saved!\")\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(loss_history, label=\"Loss\", color=\"blue\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(accuracy_history, label=\"Accuracy\", color=\"green\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGB + RF Model training"
      ],
      "metadata": {
        "id": "ifSomtjsvQkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "\n",
        "# ‚úÖ Define the ensemble model\n",
        "ensemble_emoji = VotingClassifier(\n",
        "    estimators=[\n",
        "        (\"xgb\", XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=5, use_label_encoder=False, eval_metric=\"logloss\", n_jobs=-1)),\n",
        "        (\"rf\", RandomForestClassifier(n_estimators=200, n_jobs=-1))\n",
        "    ],\n",
        "    voting=\"soft\"\n",
        ")\n",
        "\n",
        "# ‚úÖ Train the model\n",
        "ensemble_emoji.fit(X_emoji_train, y_emoji_train)\n",
        "\n",
        "# ‚úÖ Predict on test set\n",
        "y_pred_ensemble_emoji = ensemble_emoji.predict(X_emoji_test)\n",
        "\n",
        "# ‚úÖ Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_emoji_test, y_pred_ensemble_emoji)\n",
        "precision = precision_score(y_emoji_test, y_pred_ensemble_emoji, average='weighted')\n",
        "recall = recall_score(y_emoji_test, y_pred_ensemble_emoji, average='weighted')\n",
        "f1 = f1_score(y_emoji_test, y_pred_ensemble_emoji, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_emoji_test, y_pred_ensemble_emoji)\n",
        "class_report = classification_report(y_emoji_test, y_pred_ensemble_emoji)\n",
        "\n",
        "# ‚úÖ Print evaluation results\n",
        "print(f\"üöÄ Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"üß† Precision (Weighted): {precision * 100:.2f}%\")\n",
        "print(f\"üîÅ Recall (Weighted): {recall * 100:.2f}%\")\n",
        "print(f\"üéØ F1 Score (Weighted): {f1 * 100:.2f}%\\n\")\n",
        "\n",
        "print(\"üìä Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "print(\"\\nüìã Classification Report:\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "id": "0etWeqVjuyKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained emoji ensemble model\n",
        "joblib.dump(ensemble_emoji, '/content/drive/MyDrive/bully_detection/emoji_ensemble_model.pkl')\n",
        "\n",
        "print(\"‚úÖ Emoji ensemble model saved successfully!\")\n"
      ],
      "metadata": {
        "id": "lnI64x94vaHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install emoji"
      ],
      "metadata": {
        "id": "59PGfVcfqcas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import logging\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import gensim\n",
        "import joblib\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import re\n",
        "import emoji\n",
        "\n",
        "# Suppress warnings and logs\n",
        "warnings.filterwarnings('ignore')\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"huggingface_hub\").setLevel(logging.ERROR)\n",
        "\n",
        "captured_warnings = []\n",
        "def custom_warning_handler(message, category, filename, lineno, file=None, line=None):\n",
        "    captured_warnings.append(str(message))\n",
        "warnings.showwarning = custom_warning_handler\n",
        "\n",
        "# ================== Load Emoji2Vec ==================\n",
        "\n",
        "# Make sure to upload the model file to your Google Drive and update this path accordingly\n",
        "emoji2vec_path = \"/content/drive/MyDrive/bully_detection/emoji2vec.bin\"\n",
        "\n",
        "if os.path.exists(emoji2vec_path):\n",
        "    emoji2vec = gensim.models.KeyedVectors.load_word2vec_format(emoji2vec_path, binary=True)\n",
        "else:\n",
        "    raise FileNotFoundError(\"‚ùå Emoji2Vec file not found!\")\n",
        "\n",
        "# ================== Define DConvBiLSTM ==================\n",
        "class DConvBiLSTM(nn.Module):\n",
        "    def __init__(self, input_dim=768, hidden_dim=128, output_dim=2, dropout_rate=0.5):\n",
        "        super(DConvBiLSTM, self).__init__()\n",
        "        self.depthwise_conv = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, padding=1, groups=1)\n",
        "        self.bilstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim,\n",
        "                              num_layers=1, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.depthwise_conv(x)\n",
        "        x = x.squeeze(1).unsqueeze(1)\n",
        "        lstm_out, _ = self.bilstm(x)\n",
        "        out = lstm_out[:, -1, :]\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# ================== Load Models ==================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "text_model = DConvBiLSTM().to(device)\n",
        "\n",
        "# Make sure to upload the model file to your Google Drive and update this path accordingly\n",
        "text_model.load_state_dict(torch.load(\"/content/drive/MyDrive/bully_detection/dconvbilstm_bully_model.pth\", map_location=device))\n",
        "text_model.eval()\n",
        "\n",
        "# Make sure to upload the model file to your Google Drive and update this path accordingly\n",
        "emoji_classifier = joblib.load(\"/content/drive/MyDrive/bully_detection/emoji_ensemble_model_fixed.pkl\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n",
        "muril_model = AutoModel.from_pretrained(\"google/muril-base-cased\").to(device)\n",
        "muril_model.eval()\n",
        "\n",
        "# ================== Functions ==================\n",
        "def split_text_and_emoji(text):\n",
        "    \"\"\"Separate text and emojis from mixed input\"\"\"\n",
        "    emoji_list = []\n",
        "    text_list = []\n",
        "\n",
        "    for char in text:\n",
        "        if emoji.is_emoji(char):\n",
        "            emoji_list.append(char)\n",
        "        else:\n",
        "            text_list.append(char)\n",
        "\n",
        "    text_only = ''.join(text_list).strip()\n",
        "    emoji_only = ''.join(emoji_list).strip()\n",
        "\n",
        "    return text_only, emoji_only\n",
        "\n",
        "def get_muril_embedding(text):\n",
        "    tokens = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "    input_ids = tokens[\"input_ids\"].to(device)\n",
        "    attention_mask = tokens[\"attention_mask\"].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = muril_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    embedding = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
        "    return embedding\n",
        "\n",
        "def get_emoji_embedding(emoji_str):\n",
        "    if emoji_str:\n",
        "        embeddings = []\n",
        "        for emoji_char in emoji_str:\n",
        "            if emoji_char in emoji2vec:\n",
        "                embeddings.append(emoji2vec[emoji_char])\n",
        "            else:\n",
        "                embeddings.append(np.zeros(300))\n",
        "        return np.mean(embeddings, axis=0)\n",
        "    return np.zeros(300)\n",
        "\n",
        "def predict_input(user_input):\n",
        "    text_part, emoji_part = split_text_and_emoji(user_input)\n",
        "\n",
        "    text_proba = None\n",
        "    emoji_proba = None\n",
        "\n",
        "    if text_part:\n",
        "        embedding = get_muril_embedding(text_part)\n",
        "        input_tensor = torch.tensor(embedding, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            output = text_model(input_tensor)\n",
        "            text_proba = F.softmax(output, dim=1).cpu().numpy()[0]\n",
        "\n",
        "    if emoji_part:\n",
        "        emoji_features = get_emoji_embedding(emoji_part)\n",
        "        emoji_input = np.array(emoji_features).reshape(1, -1)\n",
        "        emoji_proba = emoji_classifier.predict_proba(emoji_input)[0]\n",
        "\n",
        "    if text_proba is not None and emoji_proba is not None:\n",
        "        final_proba = (text_proba + emoji_proba) / 2\n",
        "    elif text_proba is not None:\n",
        "        final_proba = text_proba\n",
        "    elif emoji_proba is not None:\n",
        "        final_proba = emoji_proba\n",
        "    else:\n",
        "        return None, \"‚ö†Ô∏è No valid input detected.\"\n",
        "\n",
        "    label = np.argmax(final_proba)\n",
        "    result = \"Bully\" if label == 1 else \"Not Bully\"\n",
        "\n",
        "    return final_proba, result, text_part, emoji_part\n",
        "\n",
        "# ================== UI Using ipywidgets ==================\n",
        "input_box = widgets.Text(value='', placeholder='Type your message with or without emoji...', description='Input:')\n",
        "predict_button = widgets.Button(description=\"Predict\")\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_predict_button_click(b):\n",
        "    user_input = input_box.value.strip()\n",
        "\n",
        "    with output:\n",
        "        output.clear_output(wait=True)\n",
        "\n",
        "        if not user_input:\n",
        "            print(\"‚ö†Ô∏è Please enter valid text or emojis.\")\n",
        "            return\n",
        "\n",
        "        final_proba, result, text_part, emoji_part = predict_input(user_input)\n",
        "\n",
        "        if final_proba is None:\n",
        "            print(\"‚ö†Ô∏è Please enter valid text or emojis.\")\n",
        "            return\n",
        "\n",
        "        if text_part:\n",
        "            print(f\"üìù Extracted Text: {text_part}\")\n",
        "        if emoji_part:\n",
        "            print(f\"üòä Extracted Emojis: {emoji_part}\")\n",
        "\n",
        "        if text_part and not emoji_part:\n",
        "            print(f\"üìù Text Model Confidence (Bully): {final_proba[1]*100:.2f}%\")\n",
        "            print(f\"üß† Final Prediction: {result}\")\n",
        "\n",
        "        elif emoji_part and not text_part:\n",
        "            print(f\"üòä Emoji Model Confidence (Bully): {final_proba[1]*100:.2f}%\")\n",
        "            print(f\"üß† Final Prediction: {result}\")\n",
        "\n",
        "        elif text_part and emoji_part:\n",
        "            print(f\"üìù Text Model Confidence (Bully): {final_proba[1]*100:.2f}%\")\n",
        "            print(f\"üòä Emoji Model Confidence (Bully): {final_proba[1]*100:.2f}%\")\n",
        "            print(f\"üß† Final Prediction: {result} (Confidence: {final_proba[np.argmax(final_proba)]*100:.2f}%)\")\n",
        "\n",
        "predict_button.on_click(on_predict_button_click)\n",
        "\n",
        "display(input_box, predict_button, output)\n"
      ],
      "metadata": {
        "id": "NmK8-sXWrHoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J2Vj76xSsSRv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVwKxN6HGMCUE1S9ANJUBr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}